{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4676f133",
   "metadata": {},
   "source": [
    "# Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3513b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/CaptSolo/BSSDH_2023_beginners/main/corpora/en_old_newspapers_5k.tsv\"\n",
    "df = pd.read_csv(url, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea61800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dariuslfuller.medium.com/creating-visuals-with-nltks-freqdist-ac4e667e49f3\n",
    "\n",
    "all_text = \"\\n\".join(df[\"Text\"]).split()\n",
    "all_fdist = FreqDist(all_text).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data to Pandas series\n",
    "all_fdist = pd.Series(dict(all_fdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matplotlib plot using Pandas attributes + xtick rotation for ease of viewing\n",
    "\n",
    "#all_plot = plt.bar(x=all_fdist.index, y=all_fdist.values, ax=ax)\n",
    "all_plot = plt.bar(all_fdist.index, all_fdist.values)\n",
    "ticks = plt.xticks(rotation=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b05161",
   "metadata": {},
   "source": [
    "### Stopword removal\n",
    "\n",
    "For widely used languages such as English we can use NLTK's stopword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb8891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's convert the list to a set (with more efficient work lookup operations)\n",
    "stopword_set = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cceaa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "all_text_stopped = [word for word in all_text if word.lower() not in stopword_set]\n",
    "\n",
    "# let's also remove some special symbols\n",
    "spec_chars = ['--', 'â€”', '-']\n",
    "all_text_stopped = [word for word in all_text_stopped if word not in spec_chars]\n",
    "\n",
    "all_text_stopped[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's draw freq distribution again\n",
    "\n",
    "all_fdist_stopped = FreqDist(all_text_stopped).most_common(20)\n",
    "all_fdist_stopped = pd.Series(dict(all_fdist_stopped))\n",
    "\n",
    "for line in all_fdist_stopped.keys():\n",
    "    print(line, \":\\t\", all_fdist_stopped[line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plot = plt.bar(all_fdist_stopped.index, all_fdist_stopped.values)\n",
    "ticks = plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33245f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plot = plt.barh(all_fdist_stopped.index, all_fdist_stopped.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2ab9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_plot = plt.barh(all_fdist_stopped.index, all_fdist_stopped.values)\n",
    "ax = plt.gca()\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44add9",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "\n",
    "Let's create histogram displaying text word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff930d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every word, return its length\n",
    "word_length = [len(word) for word in all_text]\n",
    "\n",
    "word_length[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 20\n",
    "\n",
    "plt.hist(word_length, bins=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(word_length, binwidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_words = [word for word in all_text if len(word) >= 15]\n",
    "\n",
    "long_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8572a4",
   "metadata": {},
   "source": [
    "Seaborn - histograms:\n",
    "* https://seaborn.pydata.org/tutorial/distributions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158f5d8",
   "metadata": {},
   "source": [
    "### Seaborn\n",
    "\n",
    "Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n",
    "https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9806fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FreqDist(all_text_stopped).most_common(20)\n",
    "data = pd.DataFrame(data, columns = [\"Word\",\"Frequency\"])\n",
    "\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c67e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data, x=\"Word\", y=\"Frequency\")\n",
    "\n",
    "ax = ax.set_xticklabels(data[\"Word\"], rotation=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data, y=\"Word\", x=\"Frequency\", orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cd666",
   "metadata": {},
   "source": [
    "More information about Seaborn:\n",
    "* https://seaborn.pydata.org/tutorial/introduction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea38e6d",
   "metadata": {},
   "source": [
    "### Visualizing bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e55d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.collocations as collocations\n",
    "from nltk import FreqDist, bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38807d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = bigrams(all_text_stopped)\n",
    "\n",
    "ngram_freq_list = FreqDist(ngrams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270154a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this program expects Python 3.6 or later where dictionary \n",
    "# items maintain their insertion order.\n",
    "\n",
    "ngram_dict = {}\n",
    "\n",
    "for words, count in ngram_freq_list:\n",
    "    key = \"_\".join(words)\n",
    "    ngram_dict[key] = count\n",
    "\n",
    "print(ngram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62edc7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_freqdist = pd.Series(ngram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcde3f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the figure\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "## set the plot to horizontal + set title + display  \n",
    "bar_plot = sns.barplot(x=ngram_freqdist.values, y=ngram_freqdist.index, orient='h', ax=ax)\n",
    "title = plt.title('Frequency Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c363043",
   "metadata": {},
   "source": [
    "### Stopwords for languages not included in NLTK\n",
    "\n",
    "Previously we used stopwords from NLTK stopword list but that won't work for Latvian or other languages not included in NLTK.\n",
    "\n",
    "Let's use an existing Latvian stopword list from Github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e1f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "stop_url = \"https://raw.githubusercontent.com/Xangis/extra-stopwords/master/latvian\"\n",
    "res = requests.get(stop_url)\n",
    "\n",
    "stopwords = res.text.split()\n",
    "print(stopwords[:10])\n",
    "\n",
    "stopword_set = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a89798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading our text corpus\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url_2 = \"https://raw.githubusercontent.com/CaptSolo/BSSDH_2023_beginners/main/corpora/lv_old_newspapers_5k.tsv\"\n",
    "df_2 = pd.read_csv(url_2, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ea295",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \"\\n\".join(df_2[\"Text\"]).split()\n",
    "all_fdist = FreqDist(all_text).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data to Pandas series\n",
    "all_fdist = pd.Series(dict(all_fdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "all_text_stopped = [word for word in all_text if word not in stopword_set]\n",
    "\n",
    "# removing special characters\n",
    "spec_chars = ['-', 'â€“', 'â€”']\n",
    "all_text_stopped = [word for word in all_text_stopped if word not in spec_chars]\n",
    "\n",
    "all_text_stopped[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96844ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw freq distribution\n",
    "\n",
    "all_fdist_stopped = FreqDist(all_text_stopped).most_common(20)\n",
    "all_fdist_stopped = pd.Series(dict(all_fdist_stopped))\n",
    "\n",
    "all_plot = plt.barh(all_fdist_stopped.index, all_fdist_stopped.values)\n",
    "ax = plt.gca()\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9f327",
   "metadata": {},
   "source": [
    "## Visualization examples\n",
    "\n",
    "Additional information about different Matplotlib and Seaborn visualizations:\n",
    "\n",
    "* https://matplotlib.org/stable/gallery/index.html\n",
    "* https://seaborn.pydata.org/examples/index.html\n",
    "\n",
    "Tutorials:\n",
    "\n",
    "* [Matplotlib tutorial](https://github.com/rougier/matplotlib-tutorial) by Nicolas P. Rougier\n",
    "* [Pyplot tutorial](https://matplotlib.org/stable/tutorials/introductory/pyplot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ac144",
   "metadata": {},
   "source": [
    "## Wordcloud visualization\n",
    "\n",
    "https://github.com/amueller/word_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not needed if the WordCloud library is already installed\n",
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0193cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500acf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_stopped[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(all_text_stopped)\n",
    "\n",
    "wordcloud = WordCloud().generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower max_font_size, change the maximum number of word and lighten the background:\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=40, background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud) #, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b446062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the image in a file:\n",
    "wordcloud.to_file(\"wordcloud.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab83c6c",
   "metadata": {},
   "source": [
    "Additional information about word cloud generation:\n",
    "\n",
    "* https://github.com/amueller/word_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe1057",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your turn!\n",
    "\n",
    "Choose a text corpus and **visualize it** using the tools shown in this notebook.\n",
    "\n",
    "**Write code in notebook cells below**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47dc19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d38d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95024f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
